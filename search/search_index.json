{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Chad Eline","text":"<p>Data engineering and risk analytics professional with 12+ years building production pipelines and regulatory solutions for major financial institutions.</p>"},{"location":"#what-i-do","title":"What I Do","text":"<ul> <li> <p> Data Engineering</p> <p>Production ETL pipelines, data warehousing, and cloud platform migrations</p> </li> <li> <p> Risk Management</p> <p>GARP FRM certified; CCAR, Basel, and IFRS9 implementations</p> </li> <li> <p> Forecasting &amp; Analytics</p> <p>Balance sheet, income statement, and capital planning models</p> </li> <li> <p> Applied ML</p> <p>End-to-end ML pipelines using OCR, NLP, and XGBoost in production</p> </li> </ul>"},{"location":"#highlights","title":"Highlights","text":"<ul> <li> <p> Company MVP 2023</p> <p>Led enterprise Azure migration of regulatory models, ETL pipelines, and data warehouse</p> </li> <li> <p> $17B LCR Impact</p> <p>Built FDIC calculation engine processing 163M daily records, resolving a Federal Reserve MRA</p> </li> </ul>"},{"location":"#get-in-touch","title":"Get in Touch","text":"<p> GitHub  LinkedIn</p>"},{"location":"about/","title":"About Me","text":""},{"location":"about/#background","title":"Background","text":"<p>Senior Data Engineer with 10+ years modernizing financial and regulatory analytics platforms in highly regulated environments. Proven track record leading migrations from SAS and on-premise systems to Python and Azure-based architectures. Deep experience translating risk and finance requirements into scalable data pipelines, forecasting models, and production-grade analytical systems.</p>"},{"location":"about/#experience","title":"Experience","text":""},{"location":"about/#risk-consultant-ii","title":"Risk Consultant II","text":"<p>The Financial Risk Group \u00b7 Cary, NC \u00b7 Dec 2020 \u2013 Jan 2026</p> <ul> <li>Owned migration of analytical and regulatory models from SAS/legacy systems into Python-based cloud architecture, ensuring model parity, validation, and stakeholder sign-off</li> <li>Built production data pipeline using OCR, NLP, and XGBoost to convert unstructured regulatory documents into structured, queryable datasets</li> <li>Designed and implemented Python-based PySpark job orchestration framework to improve batch reliability, monitoring, and scalability across forecasting workflows</li> <li>Led development of Balance Sheet, Income Statement, and PPNR forecasting platforms for regulatory capital planning and reporting</li> </ul> <p>Company MVP 2023</p> <p>Led large-scale migration from legacy on-premise infrastructure to Microsoft Azure:</p> <ul> <li>Basel, CCAR, and IFRS models</li> <li>Model backtesting and monitoring frameworks</li> <li>ETL pipelines and enterprise data warehouse</li> <li>De-identification and PII handling for security compliance</li> </ul>"},{"location":"about/#risk-consultant-i","title":"Risk Consultant I","text":"<p>The Financial Risk Group \u00b7 Cary, NC \u00b7 Jun 2016 \u2013 Dec 2020</p> <ul> <li>Delivered CCAR, DFAST, and IFRS9 analytical systems supporting capital planning and regulatory compliance for large financial institutions</li> <li>Consolidated forecasting platforms, retiring fragmented legacy systems and centralizing reporting pipelines into maintainable architectures</li> <li>Optimized high-volume database ingestion pipeline, reducing runtime from 4 hours to 15 minutes through partitioning, indexing, and parallelization</li> <li>Partnered with finance and risk stakeholders to define business requirements, translate regulatory logic, and validate model assumptions before production deployment</li> </ul>"},{"location":"about/#data-warehouse-solutions-architect","title":"Data Warehouse Solutions Architect","text":"<p>Bank of America \u00b7 Charlotte, NC \u00b7 Jan 2015 \u2013 Jun 2016</p> <ul> <li>Designed FDIC calculation engine processing 163 million records daily, reducing LCR outflow by $17B and resolving a Federal Reserve MRA</li> <li>Led ETL and data warehouse architecture for 40+ onshore and offshore developers; standardized development practices</li> <li>Devised technical solution for Bank of America's Federal Reserve 5G Liquidity report</li> <li>Redesigned Operational Deposits data warehouse feed, reducing runtime from 4 hours to 55 minutes</li> </ul> <p>Platinum Global Recognition Award</p> <p>Leadership and execution in resolving the FDIC MRA</p>"},{"location":"about/#software-developer-vice-president","title":"Software Developer, Vice President","text":"<p>Bank of America \u00b7 Charlotte, NC \u00b7 Mar 2014 \u2013 Dec 2014</p> <ul> <li>Implemented derivatives and collateral data warehouse with $9.67B impact on LCR reporting</li> <li>Led 25+ member development team through 70+ successful production migrations as Release Lead</li> <li>Designed and automated release process, reducing deployment from 2 days to 2 hours</li> <li>Authored 77-page development standards document establishing consistent practices</li> </ul> <p>Quote</p> <p>1 Platinum, 2 Gold, and 3 Silver Global Recognition Awards</p>"},{"location":"about/#assistant-risk-consultant","title":"Assistant Risk Consultant","text":"<p>The Financial Risk Group \u00b7 Cary, NC \u00b7 Dec 2012 \u2013 Feb 2014</p> <ul> <li>Parallelized 65-million-record daily data feed, reducing runtime from 3 days to 3 hours</li> <li>Integrated multiple source systems into enterprise ETL workflows and dimensional models</li> <li>Designed dimensional tables and ETL flows for regulatory compliance data marts</li> </ul>"},{"location":"about/#education","title":"Education","text":"<p>Emory University \u00b7 B.A. Economics \u00b7 May 2012</p>"},{"location":"about/#certifications","title":"Certifications","text":"<ul> <li> <p> Financial Risk Manager GARP Certified</p> </li> <li> <p> Base SAS 9   SAS Certified</p> </li> </ul>"},{"location":"about/#contact","title":"Contact","text":"<p> GitHub  LinkedIn</p>"},{"location":"projects/","title":"Projects","text":"<p>A showcase of personal projects and open-source tools.</p>"},{"location":"projects/#this-site","title":"This Site","text":"<ul> <li> <p> Portfolio Site</p> <p>This portfolio site, built with MkDocs Material and deployed to GitHub Pages.</p> <ul> <li>Modern &amp; minimal custom theme</li> <li>Dark/light mode toggle</li> <li>Responsive design</li> <li>CI/CD deployment via GitHub Actions</li> </ul> <p>Stack: MkDocs, Material Theme, GitHub Pages</p> <p> View on GitHub</p> </li> </ul>"},{"location":"projects/#developer-tools","title":"Developer Tools","text":"<ul> <li> <p> Resume Builder</p> <p>Generate polished MS Word resumes from Markdown files with customizable YAML templates.</p> <ul> <li>Write content in Markdown, style separately</li> <li>Multiple output formats (DOCX, PDF)</li> <li>Template inheritance and overrides</li> <li>Cover letter support</li> </ul> <p>Stack: Python, python-docx</p> <p> View on GitHub</p> </li> <li> <p> AI in Docker</p> <p>Containerized environment for running local AI/ML workloads with GPU support.</p> <ul> <li>Pre-configured for popular AI frameworks</li> <li>GPU passthrough support</li> <li>Reproducible development environment</li> <li>Easy setup and teardown</li> </ul> <p>Stack: Docker, Python, CUDA</p> <p> View on GitHub</p> </li> <li> <p> Jupyter in Docker</p> <p>Dockerized Jupyter environment for portable, reproducible data science workflows.</p> <ul> <li>Isolated notebook environments</li> <li>Pre-installed data science libraries</li> <li>Volume mounting for persistent work</li> <li>Multi-kernel support</li> </ul> <p>Stack: Docker, Jupyter, Python</p> <p> View on GitHub</p> </li> </ul>"},{"location":"projects/#want-to-collaborate","title":"Want to Collaborate?","text":"<p>I'm always interested in working on interesting projects. Feel free to reach out if you have an idea or opportunity.</p>"}]}